# 8.7 Logging, Events & Monitoring

Was ist passiert â€“ und warum?

BitGridAI ist ein autonomes, deterministisches System.  
Damit Entscheidungen nachvollziehbar, Fehler analysierbar und der Betrieb kontrollierbar bleibt, braucht es eine einheitliche Strategie fÃ¼r **Logs, Events und Monitoring**.

Dieses Kapitel beschreibt die **systemweiten Regeln** dafÃ¼r:
- was protokolliert wird,
- in welcher Form es verÃ¶ffentlicht wird,
- und wie â€Gesundheitâ€œ des Systems sichtbar gemacht wird.

*(Platzhalter fÃ¼r ein Bild: Ein Pixel-Art-Hamster mit Taschenlampe schaut in ein groÃŸes Logbuch. Daneben blinken kleine Anzeigen â€Healthâ€œ, â€Eventsâ€œ, â€Auditâ€œ.)*  
![Hamster liest die Systemspuren](link_zum_logging_hamster.png)

---

## Ziele

Logging und Monitoring in BitGridAI dienen vier Hauptzwecken:

1. **Auditierbarkeit**  
   Entscheidungen und sicherheitsrelevante Aktionen sind nachtrÃ¤glich Ã¼berprÃ¼fbar.

2. **Debuggability**  
   Fehler lassen sich reproduzieren und eingrenzen (insbesondere mit Replays).

3. **Transparenz**  
   Nutzer und Operatoren sehen, was das System tut und warum.

4. **Betriebssicherheit**  
   AusfÃ¤lle, Degradation und GrenzzustÃ¤nde werden frÃ¼h sichtbar.

---

## Grundprinzipien

- **Events sind semantisch, nicht nur textuell**  
  Wo mÃ¶glich werden strukturierte Events erzeugt, nicht nur freie Log-Zeilen.

- **Warum ist ein First-Class-Attribut**  
  Entscheidungen werden immer mit BegrÃ¼ndung/Reason erfasst.

- **Keine stillen Aktionen**  
  Safety/Stop, Degradation, abgelehnte Requests und Config-Fails sind immer sichtbar.

- **Append-only fÃ¼r relevante Historie**  
  Entscheidungs- und Safety-Ereignisse werden nicht Ã¼berschrieben.

- **Local-first**  
  Logs bleiben standardmÃ¤ÃŸig lokal (kein Telemetrie-Abfluss).

---

## Event-Typen

BitGridAI unterscheidet systemweit mehrere Event-Kategorien:

### Decision Events
Dokumentieren Entscheidungen der Rule Engine.

Enthalten typischerweise:
- Aktion (Start/Stop/Hold/â€¦)
- beteiligte Regeln (R1â€“R5)
- Reason-Code
- Trigger-Metriken (auslÃ¶sende Werte)

### Safety Events
Dokumentieren Eingriffe der Safety-Logik (R3).

Beispiele:
- Ãœbertemperatur
- fehlende Pflichtsignale
- Kommunikationsverlust

Safety Events haben immer:
- hohe PrioritÃ¤t
- klare, knappe BegrÃ¼ndung
- Sichtbarkeit in UI und Monitoring

### Health Events
Dokumentieren den Zustand von AbhÃ¤ngigkeiten und Komponenten.

Beispiele:
- MQTT unreachable
- Adapter degraded
- DB error
- Config invalid

Health Events sind Grundlage fÃ¼r:
- Statusanzeigen
- Alerts
- Degradationslogik (Kap. 8.6)

### Audit Events
Dokumentieren sicherheits- und governance-relevante VorgÃ¤nge.

Beispiele:
- Auth failed / rate limited
- Override gesetzt/abgelaufen
- Config reload success/fail
- Research export erstellt

---

## Log-Ebenen

Logs sind fÃ¼r Menschen, Events fÃ¼r Systeme.  
Beides ergÃ¤nzt sich.

Empfohlene Log-Ebenen:

- **DEBUG**: Detaildiagnostik (nur fÃ¼r Entwicklung)
- **INFO**: Normalbetrieb, wichtige Zustandswechsel
- **WARN**: Degradation, nicht-kritische Fehler, Limits erreicht
- **ERROR**: Ausfall von Pflichtkomponenten, Abbruchpfade
- **CRITICAL**: Safety Stop / gefÃ¤hrliche ZustÃ¤nde

---

## Health-Status (systemweite Semantik)

BitGridAI nutzt einen konsistenten Health-Begriff, der nach auÃŸen sichtbar ist.

- `ok`  
  Betrieb vollstÃ¤ndig mÃ¶glich.

- `warn`  
  Betrieb mÃ¶glich, aber degradiert oder mit EinschrÃ¤nkungen.

- `error`  
  PflichtabhÃ¤ngigkeiten fehlen, nur Minimalbetrieb oder Fail-safe.

Health ist:
- extern beobachtbar (UI/Monitoring)
- Quelle fÃ¼r Degradationsentscheidungen (Kap. 8.6)
- Grundlage fÃ¼r Betrieb/Alarmierung

---

## Sichtbarkeit im UI (Transparenz)

FÃ¼r Nutzer ist entscheidend:

- â€Was passiert?â€œ (Status)
- â€Warum passiert es?â€œ (Reason)
- â€Was ist die Konsequenz?â€œ (z.B. Safe/Stop)

Daher gelten Mindestanforderungen:
- aktive Safety-ZustÃ¤nde sind prominent
- Overrides sind sichtbar (inkl. TTL)
- die letzte relevante Entscheidung ist abrufbar (inkl. Trigger-Werte)

---

## Aufbewahrung & Rotation

Logs und Events folgen den Leitlinien aus Kapitel 8.3:

- operative Logs: rotierend, begrenzte Haltedauer
- relevante Events: append-only / historisch
- Forschung: Export nur per Opt-in

Low-Disk-Situationen fÃ¼hren zu:
- Warnungen/Events
- kontrollierter Rotation
- niemals zu stiller Datenkorruption

---

## Abgrenzungen

Nicht Bestandteil dieses Kapitels sind:
- konkrete Tooling-Wahl (Prometheus, Grafana, etc.)
- konkrete Log-Formate je Datei
- Dashboard-Designs

Diese Details gehÃ¶ren in Betriebs- oder Entwicklerdokumentation.

---

## Zusammenfassung

Logging, Events und Monitoring sind in BitGridAI kein â€NebengerÃ¤uschâ€œ, sondern Teil der Architektur.

Sie stellen sicher, dass:
- Entscheidungen nachvollziehbar bleiben,
- Fehler frÃ¼h sichtbar werden,
- der Betrieb kontrolliert und auditierbar ist.

BitGridAI arbeitet nicht im Verborgenen â€“ es hinterlÃ¤sst Spuren mit Bedeutung.

---

> **NÃ¤chster Schritt:** Wenn wir das System beobachten kÃ¶nnen, wollen wir es auch reproduzierbar testen.  
> Im nÃ¤chsten Abschnitt betrachten wir **Testbarkeit, Simulation & Replays**.
>
> ğŸ‘‰ Weiter zu **[8.8 Testbarkeit, Simulation & Replays](./088_testability_and_simulation.md)**
>
> ğŸ”™ ZurÃ¼ck zur **[KapitelÃ¼bersicht](./README.md)**
