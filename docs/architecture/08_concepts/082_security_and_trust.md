# 8.2 Sicherheits- & Vertrauenskonzept

Sicherheit vor Optimierung.

BitGridAI trifft Entscheidungen, die reale Auswirkungen auf Hardware, EnergieflÃ¼sse und Kosten haben.  
Deshalb ist Sicherheit kein optionales Feature, sondern eine **zentrale Systemeigenschaft**, die alle anderen Ziele Ã¼berlagert.

Dieses Kapitel beschreibt die **systemweiten Sicherheits- und Vertrauensprinzipien** von BitGridAI.  
Sie gelten unabhÃ¤ngig von Autonomie-Stufe, Betriebsmodus oder Deployment-Variante.

*(Platzhalter fÃ¼r ein Bild: Ein Pixel-Art-Hamster mit Schutzhelm steht vor einem groÃŸen roten Not-Aus-Schalter. Ein Schild: â€Safety Firstâ€œ. )*  
![Hamster schÃ¼tzt das System](link_zum_safety_hamster.png)

---

## Grundprinzipien

Das Sicherheitskonzept von BitGridAI folgt vier Ã¼bergeordneten GrundsÃ¤tzen:

1. **Safety sticht alles**  
   Sicherheitsregeln haben stets Vorrang vor Optimierung, Komfort und NutzerwÃ¼nschen.

2. **Kein Vertrauen ohne PrÃ¼fung**  
   Externe Signale, Nutzeraktionen und KonfigurationsÃ¤nderungen werden immer validiert.

3. **Klare Vertrauensgrenzen**  
   Das System unterscheidet explizit zwischen vertrauenswÃ¼rdigen und nicht-vertrauenswÃ¼rdigen Zonen.

4. **Deterministisches Fehlverhalten**  
   Bei Unsicherheit wird nicht improvisiert, sondern konservativ gehandelt.

---

## Sicherheitsregel R3 â€“ Die oberste Instanz

Die Sicherheitsregel **R3 (Safety)** ist die hÃ¶chste AutoritÃ¤t im System.

**Eigenschaften von R3:**
- nicht deaktivierbar
- nicht konfigurierbar
- nicht durch Autonomie-Stufen oder Overrides Ã¼bersteuerbar

R3 greift immer dann, wenn:
- Hardware-Grenzwerte Ã¼berschritten werden (z.B. Temperatur),
- Pflichtsignale fehlen,
- der Systemzustand nicht eindeutig bewertbar ist.

**Konsequenz:**  
R3 darf den Betrieb jederzeit stoppen oder in einen sicheren Zustand versetzen.

---

## Vertrauenszonen

BitGridAI arbeitet bewusst mit klar abgegrenzten Vertrauenszonen:

### Lokale Systemzone (Trusted)

- Core
- Rule Engine
- Persistenz
- Explain-Agent

Diese Komponenten:
- laufen auf demselben Host oder im selben LAN,
- sind integraler Bestandteil des Systems,
- gelten als vertrauenswÃ¼rdig.

---

### GerÃ¤te- & Adapterzone (Semi-Trusted)

- Sensoren
- Inverter
- Miner
- externe Adapter

Diese Quellen:
- liefern Daten oder fÃ¼hren Aktionen aus,
- kÃ¶nnen fehlerhaft, verzÃ¶gert oder manipuliert sein,
- werden niemals blind vertraut.

Alle eingehenden Signale werden:
- validiert,
- plausibilisiert,
- bei Bedarf verworfen.

---

### Nutzer- & Integrationszone (Untrusted)

- UI-Eingaben
- Home Assistant
- REST-Clients
- Research-Exporte

Diese Zugriffe:
- erfordern Authentifizierung,
- unterliegen Autorisierung und Rate-Limits,
- haben keinen direkten Zugriff auf Hardware.

---

## Authentifizierung & Autorisierung

Schreibende Zugriffe auf BitGridAI sind grundsÃ¤tzlich geschÃ¼tzt.

**Grundregeln:**
- Lesezugriffe sind restriktiv, aber niedrigschwellig.
- Schreibzugriffe erfordern explizite Berechtigung.
- Authentifizierung erfolgt lokal (keine Cloud-AbhÃ¤ngigkeit).

**Typische geschÃ¼tzte Aktionen:**
- manuelle Overrides
- Konfigurations-Reloads
- Exporte

Fehlgeschlagene Authentifizierung:
- verÃ¤ndert keinen Systemzustand,
- erzeugt nachvollziehbare Events (siehe Kap. 6.12).

---

## Rate-Limiting & Missbrauchsschutz

Zur Vermeidung von Fehlbedienung und Missbrauch gelten:

- Rate-Limits fÃ¼r alle schreibenden Endpunkte
- klare Fehlermeldungen bei Ãœberschreitung
- keine teilweise AusfÃ¼hrung

Ein abgelehnter Request:
- lÃ¶st keine Aktionen aus,
- verÃ¤ndert keine ZustÃ¤nde,
- hinterlÃ¤sst einen Audit-Eintrag.

---

## Umgang mit Unsicherheit & AusfÃ¤llen

Unsicherheit wird in BitGridAI explizit behandelt:

- fehlende Pflichtsignale â†’ Degradation
- KommunikationsabbrÃ¼che â†’ Safe- oder Stop-Zustand
- inkonsistente Konfiguration â†’ Verwerfen & Rollback

**Wichtig:**  
Unsichere Situationen fÃ¼hren niemals zu aggressiver Optimierung.

---

## Sicherheit & Autonomie

Autonomie-Stufen verÃ¤ndern, **wer entscheidet**, nicht **was erlaubt ist**.

UnabhÃ¤ngig vom Autonomie-Level gilt:
- R3 bleibt aktiv
- Safety kann nicht Ã¼bersteuert werden
- manuelle Eingriffe sind zeitlich begrenzt

Das Sicherheitskonzept ist damit **orthogonal** zur Autonomie-Logik.

---

## Sichtbarkeit & Nachvollziehbarkeit

Sicherheitsrelevante Ereignisse sind immer sichtbar:

- Safety-Events werden geloggt
- Entscheidungen enthalten BegrÃ¼ndungen
- UI signalisiert aktive Safety-ZustÃ¤nde eindeutig

Es gibt keine â€stillenâ€œ Sicherheitsaktionen.

---

## Abgrenzungen

Nicht Bestandteil dieses Kapitels sind:
- konkrete Firewall-Regeln
- TLS-Konfigurationen
- Container-Hardening im Detail

Diese Aspekte werden in der Verteilungssicht (Kap. 07) oder im Betriebshandbuch behandelt.

---

## Zusammenfassung

Das Sicherheits- und Vertrauenskonzept von BitGridAI stellt sicher, dass:

- keine Entscheidung ohne belastbare Grundlage getroffen wird,
- Sicherheit immer Vorrang hat,
- menschliche Kontrolle mÃ¶glich bleibt, ohne Risiken zu erhÃ¶hen.

Sicherheit ist kein Sonderfall â€“ sie ist der Normalzustand.

---

> **NÃ¤chster Schritt:** Sicherheit schafft Vertrauen â€“ aber VerstÃ¤ndnis schafft Akzeptanz.  
> Im nÃ¤chsten Abschnitt betrachten wir **Explainability & Transparenz**.
>
> ğŸ‘‰ Weiter zu  **[8.3 Datenhaltung & Datenlebenszyklus](./083_data_persistence.md)**  
>
> ğŸ”™ ZurÃ¼ck zur **[KapitelÃ¼bersicht](./README.md)**
