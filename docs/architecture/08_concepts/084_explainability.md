# 8.4 - Explainability & Transparenz

Verstehen ist Vertrauen.

BitGridAI trifft autonome Entscheidungen, die fÃ¼r Nutzer reale Auswirkungen haben:  
EnergieflÃ¼sse Ã¤ndern sich, Hardware startet oder stoppt, Kosten entstehen oder werden vermieden.  
Damit diese Entscheidungen akzeptiert und kontrolliert werden kÃ¶nnen, mÃ¼ssen sie **verstÃ¤ndlich und nachvollziehbar** sein.

Dieses Kapitel beschreibt die **systemweiten Prinzipien der Explainability und Transparenz** in BitGridAI.  
Explainability ist dabei kein UI-Feature, sondern ein **architektonisches Grundprinzip**, das alle Bausteine betrifft.

*(Platzhalter fÃ¼r ein Bild: Ein Pixel-Art-Hamster erklÃ¤rt einem anderen Hamster mit einer kleinen Tafel, warum ein Schalter auf â€ONâ€œ steht. Ein Sprechblasen-Symbol mit â€Warum?â€œ schwebt darÃ¼ber.)*  
![Hamster erklÃ¤rt eine Entscheidung](link_zum_explain_hamster.png)

&nbsp;

## Ziel der Explainability

Explainability in BitGridAI verfolgt drei zentrale Ziele:

1. **Nachvollziehbarkeit**  
   Nutzer sollen verstehen kÃ¶nnen, *warum* eine Entscheidung getroffen wurde.

2. **ÃœberprÃ¼fbarkeit**  
   Entscheidungen mÃ¼ssen auch nachtrÃ¤glich analysierbar und reproduzierbar sein.

3. **Vertrauensbildung**  
   Transparente Entscheidungen schaffen Akzeptanz fÃ¼r Automatisierung.

Explainability bedeutet nicht, dass das System *immer* tut, was der Nutzer erwartet â€“ sondern dass es **erklÃ¤rt, warum es anders handelt**.

&nbsp;

## Grundprinzipien

Die Explainability folgt systemweit klaren Leitlinien:

- **Warum vor Was**  
  Jede relevante Aktion ist mit einer BegrÃ¼ndung verknÃ¼pft.

- **Entscheidung â‰  ErklÃ¤rung**  
  Technische Entscheidungslogik und menschliche ErklÃ¤rung sind getrennt.

- **Read-only**  
  ErklÃ¤rungen verÃ¤ndern niemals den Systemzustand.

- **Deterministisch**  
  Gleiche Eingaben fÃ¼hren zu gleichen ErklÃ¤rungen.

- **Kontextsensitiv**  
  ErklÃ¤rungen beziehen sich auf den konkreten Zustand zum Entscheidungszeitpunkt.

&nbsp;

## Explainability im Entscheidungsprozess

Explainability ist Teil jeder Entscheidung.

Eine Entscheidung umfasst:
- die ausgefÃ¼hrte Aktion,
- die beteiligten Regeln,
- die auslÃ¶senden Faktoren.

Diese Informationen werden systematisch erfasst und stehen fÃ¼r:
- UI-Anzeigen,
- Logs,
- Replays,
- Research-Auswertungen
zur VerfÃ¼gung.

&nbsp;

## Explain Session

Eine **Explain Session** ist der formale Rahmen fÃ¼r eine ErklÃ¤rung.

Sie referenziert:
- den relevanten `EnergyState`,
- die zugehÃ¶rige Entscheidung,
- den Kontext der Nutzeranfrage (z.B. â€Warum lÃ¤uft der Miner gerade?â€œ).

Explain Sessions sind:
- zeitlich gebunden,
- unverÃ¤nderlich,
- eindeutig referenzierbar.

Sie dienen als BrÃ¼cke zwischen technischer Logik und menschlichem VerstÃ¤ndnis.

&nbsp;

## Ebenen der ErklÃ¤rung

BitGridAI unterscheidet bewusst mehrere ErklÃ¤rungsebenen:

### Kurzform (UI)

- kompakte, verstÃ¤ndliche Aussage
- z.B. â€PV-Ãœberschuss ausreichend, Batterie Ã¼ber Mindestwertâ€œ

### Detailansicht

- beteiligte Regeln
- relevante Messwerte
- Grenzwerte und Schwellen

### Technische Sicht (Audit / Replay)

- vollstÃ¤ndige Entscheidungs- und Zustandsdaten
- geeignet fÃ¼r Analyse und Forschung

Der Nutzer entscheidet, **wie tief** er einsteigen mÃ¶chte.

&nbsp;

## Explainability & Autonomie

Explainability ist unabhÃ¤ngig vom Autonomie-Level:

- im manuellen Modus erklÃ¤rt das System VorschlÃ¤ge,
- im vollautomatischen Modus erklÃ¤rt es getroffene Entscheidungen,
- bei Overrides erklÃ¤rt es, warum bestimmte Aktionen blockiert wurden (z.B. Safety).

Mehr Autonomie erfordert **mehr**, nicht weniger Transparenz.

&nbsp;

## Explainability & Sicherheit

Sicherheitsentscheidungen sind besonders erklÃ¤rungsbedÃ¼rftig.

GrundsÃ¤tze:
- Safety-Eingriffe werden immer explizit signalisiert,
- GrÃ¼nde sind klar benannt (z.B. â€Temperaturgrenze Ã¼berschrittenâ€œ),
- es gibt keine stillen Stops.

Explainability ersetzt keine SicherheitsmaÃŸnahmen, macht sie aber **verstÃ¤ndlich**.

&nbsp;

## Technische UnabhÃ¤ngigkeit

Explainability ist:
- unabhÃ¤ngig von UI-Technologie,
- unabhÃ¤ngig von konkreten LLMs,
- unabhÃ¤ngig vom Deployment-Modell.

Ob ErklÃ¤rungen durch Templates, Regeln oder Sprachmodelle erzeugt werden, ist eine Implementierungsentscheidung â€“ das Prinzip bleibt gleich.

&nbsp;

## Abgrenzungen

Nicht Bestandteil dieses Kapitels sind:
- konkrete Prompt-Templates
- UI-Layouts oder Texte
- Implementierungsdetails des Explain-Agents

Diese Details gehÃ¶ren in Entwicklungs- oder UI-Dokumentation.

&nbsp;

## Zusammenfassung

Explainability ist ein zentrales QualitÃ¤tsmerkmal von BitGridAI.

Sie stellt sicher, dass:
- Entscheidungen nachvollziehbar sind,
- Automatisierung kontrollierbar bleibt,
- Vertrauen entstehen kann, ohne Kontrolle abzugeben.

BitGridAI entscheidet nicht im Verborgenen â€“ es erklÃ¤rt sich.

---

> **NÃ¤chster Schritt:** Entscheidungen brauchen nicht nur Transparenz, sondern auch klare Grenzen menschlicher Kontrolle.  
> Im nÃ¤chsten Abschnitt betrachten wir **Autonomie, HCI & menschliche Kontrolle**.
>
> ğŸ‘‰ Weiter zu **[8.5 - Autonomie, HCI & menschliche Kontrolle](./085_autonomy_and_hci.md)**
>
> ğŸ”™ ZurÃ¼ck zur **[KapitelÃ¼bersicht](./README.md)**
