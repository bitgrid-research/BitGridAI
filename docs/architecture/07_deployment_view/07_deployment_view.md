# 07.1 Infrastruktur & Deployment

Wo der Hamster wohnt.

In dieser Sicht verlassen wir den reinen Code und betrachten die physische Welt. **BitGridAI** ist konsequent als **Local-First** System im geschlossenen LAN konzipiert. Es gibt kein Cloud-Backend, kein "Phone Home" und keinen Zwang zur Internetverbindung fÃ¼r den Regelbetrieb.

Wir definieren hier, auf welcher Hardware die Komponenten laufen, wie sie vernetzt sind und wie wir das System gegen AusfÃ¤lle und Angriffe hÃ¤rten.

*(Platzhalter fÃ¼r ein Bild: Ein Querschnitt durch ein Haus. Im Keller steht ein Server-Rack mit einem Raspberry Pi, verbunden mit Wechselrichter und Miner. Ein dicker "No Cloud"-Stempel ist auf dem Bild.)*
![Deployment Ãœbersicht](../../media/pixel_art_deployment_overview.png)

## 1. Die Zielarchitektur

Das System folgt einer klaren Pipeline: Von den Sensoren Ã¼ber die Adapter in den Core und schlieÃŸlich zur UI oder Datenbank. Der **MQTT-Broker** fungiert dabei als zentrales Nervensystem.

```mermaid
graph TD
    subgraph "Peripherie (LAN/Modbus)"
        HW_PV[â˜€ï¸ PV / Speicher]
        HW_Sens[ğŸ“ Sensoren / Meter]
        HW_Miner[â›ï¸ Mining Hardware]
    end

    subgraph "Edge Node (Controller)"
        Modules[("ğŸ”Œ Modules / Adapters<br>(Python)")]
        Core[("ğŸ§  Core + Explain-Agent<br>(Python/RuleEngine)")]
        MQTT[("ğŸ“¡ MQTT Broker<br>(Local Bus)")]
        UI[("ğŸ–¥ï¸ User Interface<br>(Svelte/HA)")]
        
        HW_PV & HW_Sens --> Modules
        Modules --> MQTT
        MQTT <--> Core
        Core --> HW_Miner
        MQTT --> UI
    end

    subgraph "Research & Data"
        DB[("ğŸ’¾ Data / Replay<br>(SQLite/Parquet)")]
        Research[("ğŸ“ Research Node<br>(Offline Analysis)")]
        
        Core --> DB
        DB -.-> Research
    end
```

## 2. Hardware & Software Stack

Worauf lÃ¤uft BitGridAI? Wir unterscheiden zwischen dem Steuerungs-Knoten und der Peripherie.

### Hardware-Komponenten

| Komponente | Rolle & Beschreibung |
| :--- | :--- |
| **Controller / Edge Node** ğŸ§  | **Der Chef.** Ein Einplatinencomputer (z.B. Raspberry Pi 4/5, Intel NUC) oder eine VM. FÃ¼hrt Core, Explain-Agent (On-Device LLM) und UI aus. |
| **PV & Speicher** â˜€ï¸ | **Die Quellen.** Wechselrichter und Batteriemanagementsysteme. Bleiben lokal via Modbus/TCP oder API erreichbar. |
| **Mining / Flexible Last** â›ï¸ | **Der Verbraucher.** ASICs oder PCs, die dynamisch als steuerbare Last agieren. Steuerung via API (z.B. Stratum/HTTP) Ã¼ber den Core. |
| **Research Terminal** ğŸ“ | **Der Analyst.** Ein optionaler, separater Rechner (Laptop/Desktop) im LAN fÃ¼r Offline-Analysen, KPI-Reports und Replays der Parquet-Logs. |

### Software-Stack

| Layer | Technologie | Zweck |
| :--- | :--- | :--- |
| **Core** | Python 3.x | Beherbergt die Regel-Engine (R1â€“R5), den BlockScheduler und die Hodl-Policy. |
| **Module** | Python / Modbus | Adapter, die proprietÃ¤re Hardware-Protokolle auf interne Events Ã¼bersetzen. |
| **Bus** | MQTT (Mosquitto) | Lokaler Austausch von State, Commands und Explain-Events in Echtzeit. |
| **UI** | Svelte / HA-Frontend | Visualisierung, Overrides und Research-Toggle. |
| **Data** | SQLite / Parquet | **SQLite:** Hot Data (aktueller EnergyState).<br>**Parquet:** Cold Data (Langzeit-Logs, effizient & append-only). |

---

## 3. Deployment-Varianten

Je nach Ausbaustufe und Zielsetzung kann BitGridAI unterschiedlich ausgerollt werden:

| Variante | Einsatzzweck | Beschreibung |
| :--- | :--- | :--- |
| **A. Standalone** | ğŸ  Standard | **"All-in-One".** Der gesamte Stack (Core, Broker, UI, DB) lÃ¤uft als Docker-Compose-Verbund auf einem einzigen Edge Device (z.B. Raspberry Pi). Ideal fÃ¼r Prototypen und Feldstudien. |
| **B. Distributed** | ğŸ¢ Skalierung | **"Verteilt".** Core und UI laufen getrennt von den Hardware-Adaptern (die z.B. nÃ¤her an den Sensoren platziert sind). Kommunikation rein Ã¼ber MQTT im LAN. Gut fÃ¼r A/B-Tests. |
| **C. Hybrid** | â˜ï¸ Optional | **"Backup".** Wie Standalone, aber mit einer *verschlÃ¼sselten*, unidirektionalen Spiegelung ausgewÃ¤hlter Logs auf einen externen Server zur Datensicherung (nur bei explizitem Opt-in). |

---

## 4. Betrieb & Sicherheit (Hardening)

Da wir physische Hardware steuern, ist Sicherheit kein Feature, sondern Pflicht.

### Netzwerk & Firewall ğŸ›¡ï¸
* **Protokolle:** MQTT (Port 1883), REST, WebSocket. Alles **nur lokal** im LAN.
* **Firewall:** Prinzip "Deny-All".
    * *Eingehend:* Nur SSH (Key-Auth), MQTT (lokal), HTTP/UI (lokal).
    * *Ausgehend:* Nur NTP (Zeit), Updates (OS/Container), Preis-API (HTTPS).
* **Kein Cloud-Backhaul:** Es gibt keinen Tunnel nach drauÃŸen. Fernzugriff erfolgt ausschlieÃŸlich via VPN (z.B. WireGuard) in das Heimnetz, nicht direkt auf das Device.

### System-Hardening ğŸ”’
* **OS:** Minimales Linux (Debian/Ubuntu Server/Raspbian Lite). Keine unnÃ¶tigen Desktop-Dienste.
* **Fail-Safe:** Bei Sensor- oder Netzwerkfehlern gilt immer: **Stop $\rightarrow$ Safe**. Das System geht in einen sicheren Zustand (Miner aus), bevor Hardware beschÃ¤digt wird.
* **Power:** Eine **USV (Unterbrechungsfreie Stromversorgung)** wird dringend empfohlen, um bei Stromausfall Datenbank-Korruption zu verhindern und einen sauberen Shutdown zu ermÃ¶glichen.

### Backup & Privacy ğŸ’¾
* **Sicherung:** TÃ¤gliches Backup von `config/` und der SQLite-DB (z.B. via BorgBackup oder Duplicati auf lokales NAS).
* **Privacy:** Keine Telemetrie standardmÃ¤ÃŸig. Research-Exports erfolgen nur, wenn der "Research-Toggle" aktiv ist (Opt-in).

---
> **NÃ¤chster Schritt:** Die Hardware steht, die Container laufen. Aber was hÃ¤lt alles im Innersten zusammen? Im nÃ¤chsten Kapitel widmen wir uns den Themen, die *alle* Bausteine betreffen.
>
> ğŸ‘‰ Weiter zu **[08 Querschnittliche Konzepte](../08_concepts/README.md)**
>
> ğŸ”™ ZurÃ¼ck zur **[KapitelÃ¼bersicht](./README.md)**
