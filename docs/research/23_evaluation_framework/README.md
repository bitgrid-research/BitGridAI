# Evaluation Framework / Evaluationsrahmen

## Ãœberblick

Das Evaluation Framework beschreibt, wie BitGridAI im Rahmen einer
Between-Subjects-Studie (Baseline vs. Explainability-Layer) bewertet wird.
Im Fokus stehen VerstÃ¤ndnis der Entscheidungslogik, Vertrauen,
wahrgenommene Kontrolle, kognitive Belastung und Energieeffizienz.

---

## Evaluationsziele

1. **ErklÃ¤rbarkeit messen** - Verstehen Nutzer die GrÃ¼nde fÃ¼r Start/Stop?
2. **Vertrauen und Kontrolle bewerten** - FÃ¼hlen sich Nutzer handlungsfÃ¤hig?
3. **Kognitive Belastung erfassen** - FÃ¼hren ErklÃ¤rungen zu Mehrbelastung?
4. **Energieeffizienz analysieren** - Welche Unterschiede zeigen sich zwischen den Varianten?
5. **Transparenzvalidierung** - Sind Logs und UI-BegrÃ¼ndungen konsistent?

---

## Studiendesign

- **Design:** Between-Subjects (Baseline-UI vs. Explainability-Layer).
- **Stichprobe:** N=10, heterogener technischer Hintergrund.
- **Dauer:** 10 Tage, tÃ¤glich 10-15 Min (Daily Diary Method).
- **Aufgaben:** Speicher/PV-Status prÃ¼fen, Laststeuerung validieren, Override testen.
- **Setting:** Smart-Home-Labor mit simulierten PV- und Batterieprofilen.

---

## Methodik

| Ebene                    | Methode                                               | Ziel                                                                  |
| ------------------------ | ----------------------------------------------------- | --------------------------------------------------------------------- |
| **Systemebene**          | Logging, Energiemessung, Baseline/XAI-Vergleich        | Bewertung von Laststeuerung, Reaktionszeiten und Effizienz           |
| **Nutzerebene**          | Daily Diary, Leitfaden-Interviews                     | Untersuchung mentaler Modelle, VerstÃ¤ndnis, Vertrauen                |
| **Interaktionsebene**    | Task-basierte Szenarien, Override-Tests               | Messung von Klarheit, Task-Zeit, Fehlerraten                           |
| **Qualitative Analyse**  | Inhaltsanalyse (Diary + Interviews)                   | Muster in Wahrnehmung, Vertrauen, KontrollgefÃ¼hl                      |
| **Quantitative Analyse** | Metriken (SUS, NASA-TLX, Energie, Vertrauen, Logs)    | Vergleichbare Kennzahlen zwischen beiden Bedingungen                  |

---

## Evaluationsumgebung

* **Hardware:** x86 Mini-PC mit UmbrelOS, UmbrelHome (4TB), Tablet fÃ¼r Dashboard,
  ASIC-Lasten (Bitaxe Gamma, NerdQaxe++), Shelly Plug S Gen3.
* **KI/ErklÃ¤rung:** lokales LLM via Ollama, quantisierte Modelle (Phi-3 Mini, Mistral 7B).
* **Sensorik:** simulierte PV- und Batterieprofile, reale ASIC-Telemetrie.
* **UI-Plattform:** lokales Dashboard in zwei Varianten (Baseline/XAI).
* **Datenerfassung:** JSON-Logs, ErklÃ¤rtexte, Nutzeraktionen.

---

## Erhebungsinstrumente

- **Daily Diary EintrÃ¤ge** (kurze tÃ¤gliche Interaktion, 10 Tage).
- **Leitfaden-Interviews** zum VerstÃ¤ndnis und Vertrauen.
- **FragebÃ¶gen:** SUS (Usability) und NASA-TLX (Belastung).
- **System-Logs:** Entscheidungen, GrÃ¼nde, Overrides, EnergieflÃ¼sse.

---

## Bewertungsmetriken

| Kategorie              | Metrik                               | Beschreibung                                                         |
| ---------------------- | ------------------------------------ | -------------------------------------------------------------------- |
| **Explainability**     | VerstÃ¤ndnisrate (%)                 | Anteil korrekt erklÃ¤rter Entscheidungen (Diary + Interview)         |
| **Trust & Control**    | Vertrauen (Likert) / Override-Rate   | Subjektives Vertrauen und Eingriffsverhalten                         |
| **Cognitive Load**     | NASA-TLX Score                       | Mentale Belastung pro Sitzung                                        |
| **Usability**          | SUS / Task-Zeit                      | Subjektive Usability und objektive Task-Dauer                         |
| **Energy Efficiency**  | kWh-Einsparung                       | Differenz zwischen Baseline und Explainability-Variante              |
| **Transparency**       | Log-Konsistenz                       | Vergleich interner Entscheidung und UI-BegrÃ¼ndung                   |

---

## Auswertung & Dokumentation

* Vergleich der beiden UI-Varianten (Baseline vs. Explainability) auf allen Metriken.
* Triangulation aus Logs, Diarys, Interviews und FragebÃ¶gen.
* Ergebnisdokumentation in Notebooks oder internen Dashboards
  mit Fokus auf ErklÃ¤rqualitÃ¤t, Vertrauen und Nutzbarkeit.

---

## Zusammenfassung

Der Evaluationsrahmen verbindet technische Messdaten mit Nutzerwahrnehmung,
um die Wirkung eines erklÃ¤renden KI-Layers auf VerstÃ¤ndnis, Vertrauen,
Kontrolle und Belastung zu prÃ¼fen. Die Studie liefert damit belastbare
Gestaltungsimpulse fÃ¼r transparente, lokal ausgefÃ¼hrte Energiesysteme.

---

> **NÃ¤chster Schritt:** Der Evaluationsrahmen steht.
> Im nÃ¤chsten Kapitel folgt die LiteraturÃ¼bersicht.
>
> ğŸ‘‰ Weiter zu **[29 - LiteraturÃ¼bersicht](../29_literature_review/README.md)**
>
> ğŸ”™ ZurÃ¼ck zu **[2 - Forschung](../README.md)**
>
> ğŸ  ZurÃ¼ck zur **[HauptÃ¼bersicht](../../README.md)**
