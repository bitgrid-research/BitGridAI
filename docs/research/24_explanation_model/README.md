# 24 â€“ ErklÃ¤rungsmodell

Dieses Kapitel beschreibt das **ErklÃ¤rungsmodell** des Systems. Es definiert, **wie Entscheidungen erklÃ¤rt werden**, aus welchen **Bestandteilen** sich eine ErklÃ¤rung zusammensetzt und wie diese **systematisch aus der Entscheidungslogik** (Kapitel 23) abgeleitet wird.

Der Fokus liegt nicht auf der Darstellung einzelner UI-Elemente, sondern auf einem **konzeptionellen Modell**, das sicherstellt, dass ErklÃ¤rungen:

* konsistent,
* nachvollziehbar,
* und Ã¼ber verschiedene Interfaces hinweg wiederverwendbar sind.

&nbsp;


## Ziel des ErklÃ¤rungsmodells

Das ErklÃ¤rungsmodell verfolgt drei zentrale Ziele:

1. **Transparenz von Entscheidungen**
   Nutzer sollen verstehen kÃ¶nnen, *warum* das System gehandelt oder bewusst nicht gehandelt hat.
2. **Konsistenz Ã¼ber Systemgrenzen hinweg**
   Dieselbe Entscheidung soll in Logs, UI und Analyse gleich begrÃ¼ndet werden.
3. **Reduktion kognitiver Belastung**
   ErklÃ¤rungen sollen kurz, strukturiert und situationsangemessen sein.

Das Modell versteht ErklÃ¤rungen als **systematische Ableitung aus Regeln und ZustÃ¤nden**, nicht als nachtrÃ¤gliche Rechtfertigung.

&nbsp;

## ErklÃ¤rung als strukturierte Bausteine

Jede ErklÃ¤rung wird als Kombination klar definierter **Bausteine** verstanden. Diese Bausteine sind unabhÃ¤ngig vom Interface und kÃ¶nnen je nach Kontext unterschiedlich dargestellt werden.

## Baustein 1 â€“ AuslÃ¶ser

Der AuslÃ¶ser beschreibt, **welche Bedingung oder Regelkonstellation** zu einer Entscheidung gefÃ¼hrt hat.

Beispiele:

* Erreichen oder Unterschreiten eines Schwellenwerts,
* Ablauf eines Zeitfensters,
* Sicherheitsereignis.

Der AuslÃ¶ser beantwortet die Frage:

> *Was hat diese Entscheidung ausgelÃ¶st?*

&nbsp;

## Baustein 2 â€“ Datenbasis

Die Datenbasis benennt die **relevanten Zustandsdaten**, auf die sich die Entscheidung stÃ¼tzt.

Beispiele:

* PV-Ãœberschuss,
* Ladezustand des Speichers,
* Temperatur,
* Prognosezustand.

Die Datenbasis beantwortet die Frage:

> *Worauf stÃ¼tzte sich das System?*

&nbsp;

## Baustein 3 â€“ Wirkung

Die Wirkung beschreibt, **was das System entschieden hat**.

Beispiele:

* Starten,
* Stoppen,
* Drosseln,
* bewusstes Nicht-Handeln (`NOOP`).

Dieser Baustein beantwortet die Frage:

> *Was hat das System getan (oder nicht getan)?*

&nbsp;

## Baustein 4 â€“ Optionen (implizit oder explizit)

Der Options-Baustein beschreibt, **welche Alternativen prinzipiell mÃ¶glich gewesen wÃ¤ren**, auch wenn sie nicht gewÃ¤hlt wurden.

Beispiele:

* Start wÃ¤re ohne Deadband mÃ¶glich gewesen,
* Weiterbetrieb wÃ¤re ohne Sicherheitslimit erlaubt gewesen.

Dieser Baustein beantwortet die Frage:

> *Was hÃ¤tte das System grundsÃ¤tzlich auch tun kÃ¶nnen?*

Optionen mÃ¼ssen nicht immer angezeigt werden, sind aber fÃ¼r Analyse und Vertrauen relevant.

&nbsp;

## Ableitung von ErklÃ¤rungen aus Entscheidungsregeln

ErklÃ¤rungen werden **direkt aus der Entscheidungslogik** abgeleitet:

* Jede Entscheidung basiert auf einem Satz von **RegelzustÃ¤nden** (R1â€“R5).
* Diese RegelzustÃ¤nde werden in **menschlich verstÃ¤ndliche Aussagen** Ã¼bersetzt.
* Die Ãœbersetzung folgt festen Mustern, keine freien Texte.

### Beispielhafte Ableitung

RegelzustÃ¤nde:

* R1: erfÃ¼llt
* R2: erfÃ¼llt
* R3: erfÃ¼llt
* R4: blockiert
* R5: erfÃ¼llt

Abgeleitete ErklÃ¤rung:

> â€Kein Start: Prognose instabil, obwohl Energie- und Speicherbedingungen erfÃ¼llt sind.â€œ

Damit bleibt die ErklÃ¤rung:

* regelbasiert,
* Ã¼berprÃ¼fbar,
* konsistent Ã¼ber alle Systemebenen.

&nbsp;

## ErklÃ¤rung von Nicht-Handeln (NOOP)

Ein zentrales Element des ErklÃ¤rungsmodells ist die explizite ErklÃ¤rung von **bewusstem Nicht-Handeln**.

Annahmen:

* Nicht-Handeln ist eine **aktive Entscheidung**, kein Systemfehler.
* Gerade in ruhigen Systemen ist NOOP der hÃ¤ufigste Entscheidungsfall.

Beispiele:

* â€Keine Aktion: Mindestpause noch aktiv.â€œ
* â€Keine Aktion: Sicherheitsreserve wird gehalten.â€œ

Die ErklÃ¤rung von NOOP ist entscheidend fÃ¼r:

* Vertrauen,
* mentale Modelle,
* spÃ¤tere Optimierung und Analyse.

&nbsp;

## Konsistenz zwischen Logs, UI und Analyse

Das ErklÃ¤rungsmodell fordert eine **einheitliche semantische Grundlage** fÃ¼r alle ErklÃ¤rungen:

* Logs enthalten strukturierte RegelzustÃ¤nde und Entscheidungen.
* UI-Texte werden aus denselben Bausteinen generiert.
* Analyse- und Evaluationsschritte greifen auf identische Bedeutungen zurÃ¼ck.

Unterschiede bestehen ausschlieÃŸlich in:

* Detailtiefe,
* Darstellung,
* zeitlicher Perspektive.

Damit wird verhindert, dass UI-ErklÃ¤rungen und Systemlogs widersprÃ¼chliche Aussagen machen.

&nbsp;

## Einordnung

Das ErklÃ¤rungsmodell bildet die **BrÃ¼cke zwischen Systemlogik und Nutzerwahrnehmung**.
Es stellt sicher, dass Entscheidungen nicht nur korrekt, sondern auch **kommunizierbar und Ã¼berprÃ¼fbar** sind.

Auf dieser Basis kann im nÃ¤chsten Kapitel beschrieben werden, **wie diese ErklÃ¤rungen konkret im Interface dargestellt werden**.




---

> **NÃ¤chster Schritt:** Das ErklÃ¤rungsmodell steht.
> Im nÃ¤chsten Kapitel folgt das Interface Design.
>
> ğŸ‘‰ Weiter zu **[25 - Interface Design](../25_interface_design/README.md)**
>
> ğŸ”™ ZurÃ¼ck zu **[2 - Forschung](../README.md)**
>
> ğŸ  ZurÃ¼ck zur **[HauptÃ¼bersicht](../../README.md)**
