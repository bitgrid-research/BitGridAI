# 20.2.2 - AUTO-CONTEXT - Automotive-Kontext

Der Automotive-Kontext fokussiert die Frage:
"Warum lÃ¤dt mein Auto gerade - oder warum nicht - und wie erklÃ¤rt mir das System die Entscheidung?"

Hier steht nicht die Optimierung im Vordergrund, sondern VerstÃ¤ndnis, Vertrauen
und eine saubere, alltagstaugliche ErklÃ¤rung im Fahrzeug.

<img src="../../../../media/context_auto.png" alt="Hamster tech" width="400">

&nbsp;

## Zielbild

1. Das E-Auto als erklÃ¤render, steuerbarer Akteur im Smart-Grid / HEMS.  
2. Ladeentscheidungen werden nicht nur angezeigt, sondern kausal begrÃ¼ndet.  
3. Eine lokale Explainable-Layer (â€Transparent Energy Personaâ€œ) Ã¼bersetzt
   - Regeln (R1â€“R5),
   - SystemzustÃ¤nde,
   - Prognosen,
   
   in verstÃ¤ndliche Alltagssprache und Ã¼bertrÃ¤gt sie ins Fahrzeug-UI.


&nbsp;

## Bezug zu den zentralen Arbeitsfragen

Der Automotive-Kontext operationalisiert die drei Dimensionen:
### WQ1 â€“ Transparenz
- **[20.2.2.1 - AUTO-WQ1 - Verstehen der Ladeentscheidung](./2022a_transparenz.md)**
  - *Welche systeminternen Informationen mÃ¼ssen sichtbar werden, damit der Fahrer in <2 Sekunden versteht, warum geladen wird oder nicht?*

### WQ2 â€“ Kontrolle
- **[20.2.2.2 - AUTO-WQ2 - Kontrolle im Auto](./2022b_kontrolle.md)**
  - *Welche minimalen Override-Optionen sind notwendig, damit die Automatik als kontrollierbar wahrgenommen wird?*

### WQ3 â€“ Vertrauen
- **[20.2.2.3 - AUTO-WQ3 - Vertrauen und Reichweitenangst](./2022c_vertrauen.md)**
  - *Wie kÃ¶nnen Sicherheitsreserven (Pendlerpuffer, Reichweitenzusagen) so visualisiert werden, dass Reichweitenangst reduziert und Vertrauen stabilisiert wird?*


&nbsp;

## Interaktionsprinzipien im Fahrzeug

Abgeleitet aus Blickdauer, Nutzungskontext und den Annahmen der Deep Dives:

- Erfassbarkeit in maximal 2 Sekunden (Glanceability).
- Reihenfolge der Information:  
  **Warum â†’ Wann â†’ Was kann ich tun?**
- Alltagssprache statt technischer Regelbezeichnungen.
- Ein-Tap-Override (â€Jetzt ladenâ€œ).
- Sichtbare Sicherheitsreserve (â€Bereit fÃ¼r morgen: Ja/Neinâ€œ).
- Keine tiefen MenÃ¼s, keine komplexen Diagramme.


&nbsp;

## User Journey (Kurzform)

1) Ankommen: Auto wird angesteckt, System entscheidet (z. B. Warten auf PV).
2) ErklÃ¤rung: Persona nennt Grund + erwarteten Startzeitpunkt.
3) Kontrolle: Nutzer kann einmalig Ã¼berschreiben.
4) Ergebnis: VerstÃ¤ndnis statt "Warum passiert nichts?".

&nbsp;

## Beispielmeldungen

- â€Ich pausiere kurz, der Strom ist gerade teuer. In 20 Minuten wird er gÃ¼nstiger.â€œ
- â€Ich warte auf mehr Sonne. Start voraussichtlich um 14:10.â€œ
- â€Dein Pendler-Puffer ist gesichert. Das Haus nutzt nur den Rest.â€œ
- â€Okay, ich lade jetzt mit Netzstrom. Das kostet heute etwa 2 â‚¬ mehr.â€œ

> **Transparent Energy Persona (Explainable Layer)**
>
> TonalitÃ¤t: ruhig, hilfreich, vorausschauend.
> 
> Prinzip: erst warum, dann was, dann wann.
> 
> Kurz, alltagssprachlich und â€glanceableâ€œ, keine Fachbegriffe ohne Nachfrage.



&nbsp;

## Konzept

Stand: 19.01.2026: https://slate-bronze-73147930.figma.site/ 


&nbsp;

## Offene Fragen

- Welche ErklÃ¤rungslÃ¤nge ist im Auto noch verstÃ¤ndlich?
- Welche Trigger sind "proaktiv genug" ohne zu stÃ¶ren?
- Welche Visualisierung ersetzt komplexe Diagramme?

---

> **NÃ¤chster Schritt:** Danach folgen die Kontext- und Diskussionsfragen,
> die den Ansatz reflektieren und abgrenzen.
>
> ğŸ‘‰ Weiter zu **[20.3 - DQ - Kontext- und Diskussionsfragen](../../203_discussion_questions/README.md)**
>
> ğŸ”™ ZurÃ¼ck zu **[20.2 - WQ - Zentrale Arbeitsfragen](../README.md)**
>
> ğŸ”™ ZurÃ¼ck zur **[ForschungsÃ¼bersicht](../../../README.md)**
>
> ğŸ  ZurÃ¼ck zur **[HauptÃ¼bersicht](../../../../README.md)**
